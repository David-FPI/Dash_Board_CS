import streamlit as st
import pandas as pd
import re
import io
st.set_page_config(page_title="Tá»•ng há»£p bÃ¡o cÃ¡o nhÃ¢n viÃªn", layout="wide")
st.title("ğŸ“Š Tá»•ng há»£p bÃ¡o cÃ¡o nhÃ¢n viÃªn tá»« nhiá»u file Excel")

# ======================== HÃ m chuáº©n hÃ³a & xá»­ lÃ½ ========================
def normalize_staff_name(name):
    if not isinstance(name, str):
        return ""
    name = re.sub(r"\(.*?\)", "", name)
    name = re.sub(r"\s+", " ", name).strip()
    return name

def extract_header(df):
    if len(df) < 3:
        raise ValueError("File thiáº¿u dÃ²ng tiÃªu Ä‘á» (Ã­t hÆ¡n 3 dÃ²ng).")
    row1 = df.iloc[1].fillna("")
    row2 = df.iloc[2].fillna("")
    header = row1.astype(str) + " " + row2.astype(str)
    header = header.str.replace(r"\s+", " ", regex=True).str.strip()
    return header

def extract_data_block(df_raw):
    header = extract_header(df_raw)
    header = pd.Series(header)
    header = header.where(~header.duplicated(), header + "_" + header.groupby(header).cumcount().astype(str))
    df_data = df_raw.iloc[3:].copy()

    cutoff_idx = df_data[df_data.iloc[:, 0].astype(str).str.contains("ç»Ÿè®¡|Tá»•ng", case=False, na=False)].index
    if not cutoff_idx.empty:
        df_data = df_data.loc[:cutoff_idx[0] - 1]

    df_data.columns = header
    df_data.reset_index(drop=True, inplace=True)

    staff_col = next((c for c in df_data.columns if "nhÃ¢n viÃªn" in c.lower()), None)
    if not staff_col:
        raise ValueError("KhÃ´ng tÃ¬m tháº¥y cá»™t NhÃ¢n viÃªn.")

    last_name = None
    for i in range(len(df_data)):
        name = df_data.at[i, staff_col]
        if pd.notna(name) and str(name).strip() != "":
            last_name = normalize_staff_name(name)
        elif last_name:
            df_data.at[i, staff_col] = last_name

    return df_data

# ======================== Xá»­ lÃ½ nhiá»u sheet ========================
def process_all_sheets(file):
    xls = pd.ExcelFile(file)
    all_data = []
    log = []
    for sheet in xls.sheet_names:
        try:
            df_raw = xls.parse(sheet, header=None)
            cleaned = extract_data_block(df_raw)
            cleaned["__Sheet__"] = sheet
            all_data.append(cleaned)
            log.append({"Sheet": sheet, "Status": "âœ… ÄÃ£ xá»­ lÃ½", "Rows": len(cleaned)})
        except Exception as e:
            log.append({"Sheet": sheet, "Status": f"âŒ Bá» qua - {str(e)}", "Rows": 0})
    log_df = pd.DataFrame(log)
    return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame(), log_df

# ======================== Chuáº©n hÃ³a tÃªn cá»™t ========================
def normalize_column_name(col):
    col = str(col)
    col = re.sub(r"\s+", " ", col)
    col = col.strip().lower()
    return col

# ======================== Giao diá»‡n ========================
uploaded_files = st.file_uploader("ğŸ“ Táº£i lÃªn 1 hoáº·c nhiá»u file bÃ¡o cÃ¡o Excel", type=["xlsx"], accept_multiple_files=True)

if uploaded_files:
    full_data = []
    for file in uploaded_files:
        try:
            st.success(f"âœ”ï¸ Äang xá»­ lÃ½: {file.name}")
            df_all, sheet_log = process_all_sheets(file)
            df_all["__File__"] = file.name
            full_data.append(df_all)
        except Exception as e:
            st.error(f"âŒ Lá»—i khi xá»­ lÃ½ file {file.name}: {e}")

    if full_data:
        df_final = pd.concat(full_data, ignore_index=True)
        # ğŸ” In thá»­ cÃ¡c sheet vÃ  sá»‘ cá»™t nháº­n Ä‘Æ°á»£c tá»« má»—i sheet
        st.markdown("### ğŸ“Œ Check: Cá»™t nháº­n Ä‘Æ°á»£c tá»« má»—i sheet")

        if "__Sheet__" in df_final.columns:
            sheet_col_map = df_final.groupby("__Sheet__").agg(lambda x: list(x.index)).reset_index()
            sheet_col_map["Sá»‘ dÃ²ng"] = sheet_col_map["__Sheet__"].apply(lambda sheet: len(df_final[df_final["__Sheet__"] == sheet]))
            sheet_col_map["Sá»‘ cá»™t"] = sheet_col_map["__Sheet__"].apply(lambda sheet: df_final[df_final["__Sheet__"] == sheet].shape[1])
            st.dataframe(sheet_col_map[["__Sheet__", "Sá»‘ dÃ²ng", "Sá»‘ cá»™t"]], use_container_width=True)

            # Optional: hiá»ƒn thá»‹ 3 dÃ²ng Ä‘áº§u cá»§a má»—i sheet
            for sheet in df_final["__Sheet__"].unique():
                st.markdown(f"#### ğŸ§¾ Sheet: {sheet} - 3 dÃ²ng Ä‘áº§u")
                st.dataframe(df_final[df_final["__Sheet__"] == sheet].head(3), use_container_width=True)
        else:
            st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y cá»™t '__Sheet__'. CÃ³ thá»ƒ hÃ m process_all_sheets() Ä‘ang bá»‹ lá»—i.")




        st.subheader("âœ… Dá»¯ liá»‡u Ä‘Ã£ tá»•ng há»£p")
        st.dataframe(df_final.head(50), use_container_width=True)

        # â€”â€”â€”â€”â€”â€” START: TÃNH KPI â€”â€”â€”â€”â€”â€”
        normalized_cols = {c: normalize_column_name(c) for c in df_final.columns}

        kpi_ketban_keywords = ["tá»•ng sá»‘ káº¿t báº¡n trong ngÃ y", "å½“å¤©åŠ zaloæ€»æ•°"]
        kpi_tuongtac_keywords = ["tÆ°Æ¡ng tÃ¡c â‰¥10 cÃ¢u", "â‰¥10"]
        kpi_groupzalo_keywords = ["tham gia group zalo", "lÆ°á»£ng tham gia group zalo"]
        # --- CÃC KPI Má» Rá»˜NG Má»šI ---
        kpi_1_1_keywords = ["trao Ä‘á»•i 1-1", "ç§ä¿¡zaloæ•°", "tá»•ng trao Ä‘á»•i trong ngÃ y"]
        kpi_duoi10_keywords = ["<10"]
        kpi_khong_phan_hoi_keywords = ["khÃ´ng pháº£n há»“i", "æ— å›å¤", "æ— "]

        # GÃ¡n tiÃªu Ä‘á» gá»‘c Ä‘á»ƒ gáº¯n nhÃ£n dá»… hiá»ƒu
        kpi_label_map = {}
 

        def find_cols_by_keywords(keywords, kpi_name=None):
            found = []
            for orig, norm in normalized_cols.items():
                if any(kw in norm for kw in keywords):
                    found.append(orig)
                    if kpi_name:
                        kpi_label_map[kpi_name] = orig  # chá»‰ lÆ°u 1 tiÃªu Ä‘á» Ä‘áº§u tiÃªn
            return found

        # def find_cols_by_keywords(keywords):
        #     return [orig for orig, norm in normalized_cols.items() if any(kw in norm for kw in keywords)]

        def find_col_by_keywords(keywords):
            return next((orig for orig, norm in normalized_cols.items()
                        if any(kw in norm for kw in keywords)), None)

        cols_ketban = find_cols_by_keywords(kpi_ketban_keywords)
        cols_tuongtac = find_cols_by_keywords(kpi_tuongtac_keywords)
        cols_groupzalo = find_cols_by_keywords(kpi_groupzalo_keywords)
        cols_1_1 = find_cols_by_keywords(kpi_1_1_keywords)
        cols_duoi10 = find_cols_by_keywords(kpi_duoi10_keywords)
        cols_khong_phan_hoi = find_cols_by_keywords(kpi_khong_phan_hoi_keywords)
        # === Bá»• sung cÃ¡c nhÃ³m KPI má»›i ===
        kpi_luong_data_kh_keywords = ["å¼¹çª—", "å®¢æˆ·è”ç³»ç¤¾äº¤åª’ä½“", "khÃ¡ch hÃ ng nháº¯n tin", "æµé‡"]
        kpi_zalo_meta_moi_keywords = ["ï¼ˆæ–°ï¼‰"]
        kpi_zalo_meta_cu_keywords = ["ï¼ˆè€ï¼‰"]
        kpi_zalo_meta_keywords = ["ç¤¾äº¤åª’ä½“åŠ zaloå¥½å‹"]
        kpi_zalo_sdt_moi_keywords = ["sdtåŠ zaloå¥½å‹æ–°"]
        kpi_zalo_sdt_cu_keywords = ["sdtåŠ zaloå¥½å‹è€"]
        kpi_zalo_sdt_keywords = ["sdtåŠ zaloå¥½å‹"]

        # Táº¡o set Ä‘á»ƒ loáº¡i trá»« trÃ¹ng láº·p
        used_cols = set(cols_ketban + cols_tuongtac + cols_groupzalo + cols_1_1 + cols_duoi10 + cols_khong_phan_hoi)

        def find_col_exclude_used(keywords):
            for orig, norm in normalized_cols.items():
                if orig not in used_cols and any(kw in norm for kw in keywords):
                    used_cols.add(orig)
                    return orig
            return None
        
        # DÃ² tá»«ng cá»™t vÃ  gÃ¡n vÃ o df_final náº¿u tÃ¬m Ä‘Æ°á»£c
        kpi_extra_mapping = {
            "kpi_luong_data_kh": find_col_exclude_used(kpi_luong_data_kh_keywords),
            "kpi_zalo_meta_moi": find_col_exclude_used(kpi_zalo_meta_moi_keywords),
            "kpi_zalo_meta_cu": find_col_exclude_used(kpi_zalo_meta_cu_keywords),
            "kpi_zalo_meta": find_col_exclude_used(kpi_zalo_meta_keywords),
            "kpi_zalo_sdt_moi": find_col_exclude_used(kpi_zalo_sdt_moi_keywords),
            "kpi_zalo_sdt_cu": find_col_exclude_used(kpi_zalo_sdt_cu_keywords),
            "kpi_zalo_sdt": find_col_exclude_used(kpi_zalo_sdt_keywords)
        }


        for kpi_name, col_name in kpi_extra_mapping.items():
            if col_name:
                df_final[kpi_name] = pd.to_numeric(df_final[col_name], errors="coerce").fillna(0)



        if not (cols_ketban and cols_tuongtac and cols_groupzalo):
            st.warning("âš ï¸ KhÃ´ng tÃ¬m Ä‘á»§ 3 cá»™t KPI (káº¿t báº¡n, tÆ°Æ¡ng tÃ¡c, group Zalo). Vui lÃ²ng kiá»ƒm tra láº¡i tÃªn cá»™t.")
        else:
            df_final["kpi_ketban"] = df_final[cols_ketban].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)
            df_final["kpi_tuongtac_tren_10"] = df_final[cols_tuongtac].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)
            df_final["kpi_groupzalo"] = df_final[cols_groupzalo].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)
            df_final["kpi_traodoi_1_1"] = df_final[cols_1_1].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)
            df_final["kpi_doi_thoai_duoi_10"] = df_final[cols_duoi10].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)
            df_final["kpi_khong_phan_hoi"] = df_final[cols_khong_phan_hoi].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)




            
            # ğŸ¯ NÃ¢ng cáº¥p tÃ¬m cá»™t NhÃ¢n viÃªn vÃ  Nguá»“n
            staff_keywords = ["nhÃ¢n viÃªn", "äººå‘˜", "æˆå‘˜"]
            source_keywords = ["nguá»“n", "æ¸ é“"]

            staff_col = find_col_by_keywords(staff_keywords)
            source_col = find_col_by_keywords(source_keywords)

            kpi_cols = [
                "kpi_luong_data_kh", "kpi_zalo_meta_moi", "kpi_zalo_meta_cu", "kpi_zalo_meta",
                "kpi_zalo_sdt_moi", "kpi_zalo_sdt_cu", "kpi_zalo_sdt",
                "kpi_ketban", "kpi_traodoi_1_1", "kpi_doi_thoai_duoi_10", "kpi_tuongtac_tren_10",   
                "kpi_khong_phan_hoi",           "kpi_groupzalo"

            ]



            # Dá»±a vÃ o logic dÃ² cá»™t trong code cá»§a báº¡n, Ä‘Ã¢y lÃ  pháº§n nÃªn thÃªm Ä‘á»ƒ dÃ² thÃªm 3 cá»™t:
            #   - "AI1" => kpi_ai1
            #   - "Block Chain1" => kpi_block_chain1
            #   - "Web31" => kpi_web31

            # Bá»• sung tá»« khÃ³a cho cÃ¡c KPI nÃ y:
            kpi_ai1_keywords = ["ai1"]
            kpi_block_chain1_keywords = ["block chain1"]
            kpi_web31_keywords = ["web31"]

            # ThÃªm vÃ o sau cÃ¡c pháº§n dÃ² cá»™t má»Ÿ rá»™ng khÃ¡c:
            kpi_extra_mapping.update({
                "kpi_ai1": find_col_exclude_used(kpi_ai1_keywords),
                "kpi_block_chain1": find_col_exclude_used(kpi_block_chain1_keywords),
                "kpi_web31": find_col_exclude_used(kpi_web31_keywords)
            })

            # GÃ¡n giÃ¡ trá»‹ vÃ o df_final náº¿u cá»™t tá»“n táº¡i:
            for kpi_name in ["kpi_ai1", "kpi_block_chain1", "kpi_web31"]:
                col_name = kpi_extra_mapping.get(kpi_name)
                if col_name:
                    df_final[kpi_name] = pd.to_numeric(df_final[col_name], errors="coerce").fillna(0)
                    kpi_cols.append(kpi_name)



            df_kpi = df_final.groupby([staff_col, source_col], as_index=False)[kpi_cols].sum()
            st.subheader("ğŸ“ˆ KPI theo nhÃ¢n viÃªn vÃ  nguá»“n")
            st.dataframe(df_kpi, use_container_width=True)



            df_kpi_total = df_kpi.groupby(staff_col, as_index=False)[kpi_cols].sum()
            df_kpi_total.insert( df_kpi_total.columns.get_loc("kpi_khong_phan_hoi") + 1, "kpi_ty_le_phan_hoi (%)",   ((df_kpi_total["kpi_traodoi_1_1"] - df_kpi_total["kpi_khong_phan_hoi"]) / df_kpi_total["kpi_traodoi_1_1"] * 100).round(2))
            # â• ThÃªm dÃ²ng Tá»•ng cá»™ng
            total_row = df_kpi_total[kpi_cols].sum(numeric_only=True)
            total_row[staff_col] = "Tá»•ng cá»™ng"


            # TÃ­nh láº¡i kpi_ty_le_phan_hoi (%) cho dÃ²ng Tá»•ng cá»™ng
            # TÃ­nh láº¡i kpi_ty_le_phan_hoi (%) cho dÃ²ng Tá»•ng cá»™ng
            try:
                tong_traodoi = total_row.get("kpi_traodoi_1_1", 0)
                tong_khong_phan_hoi = total_row.get("kpi_khong_phan_hoi", 0)
                if tong_traodoi != 0:
                    ty_le = round((tong_traodoi - tong_khong_phan_hoi) / tong_traodoi * 100, 2)
                    total_row["kpi_ty_le_phan_hoi (%)"] = f"{ty_le:.2f}%"
                else:
                    total_row["kpi_ty_le_phan_hoi (%)"] = ""
            except:
                total_row["kpi_ty_le_phan_hoi (%)"] = ""

            df_kpi_total = pd.concat([df_kpi_total, pd.DataFrame([total_row])], ignore_index=True)
            # ğŸ” Kiá»ƒm tra tá»•ng chi tiáº¿t cÃ³ khá»›p vá»›i kpi_traodoi_1_1 khÃ´ng
            tong_chi_tiet = (
                df_kpi_total["kpi_doi_thoai_duoi_10"] +
                df_kpi_total["kpi_tuongtac_tren_10"] +
                df_kpi_total["kpi_khong_phan_hoi"]
            )
            
            chenh_lech = df_kpi_total["kpi_traodoi_1_1"] - tong_chi_tiet
            
            # Ghi chÃº: Náº¿u Ä‘Ãºng thÃ¬ 'Yes', náº¿u sai thÃ¬ 'No (+x)'
            df_kpi_total["kpi_check_1_1"] = chenh_lech.apply(lambda x: "Yes" if x == 0 else f"No ({x:+.0f})")

            # ===== ğŸ”§ KPI tÃ¹y biáº¿n (cá»™ng trá»« nhÃ¢n chia giá»¯a cÃ¡c cá»™t) =====
            with st.expander("ğŸ§® Thiáº¿t káº¿ cÃ´ng thá»©c KPI tuá»³ biáº¿n", expanded=False):
                col_names = df_kpi_total.columns.tolist()
                selected_cols = st.multiselect("ğŸ“Œ Chá»n cá»™t muá»‘n dÃ¹ng trong cÃ´ng thá»©c:", col_names, default=[])

                common_formulas = {
                    "Hiá»‡u suáº¥t group / káº¿t báº¡n (%)": "kpi_groupzalo / kpi_ketban * 100",
                    "Tá»‰ lá»‡ khÃ´ng pháº£n há»“i": "kpi_khong_phan_hoi / kpi_traodoi_1_1 * 100",
                    "TÆ°Æ¡ng tÃ¡c >10 / káº¿t báº¡n (%)": "kpi_tuongtac_tren_10 / kpi_ketban * 100"
                }
                selected_common = st.selectbox("ğŸ“‚ Chá»n cÃ´ng thá»©c máº«u:", [""] + list(common_formulas.keys()))
                if selected_common:
                    custom_formula = common_formulas[selected_common]
                    st.info(f"ğŸ“Œ CÃ´ng thá»©c Ä‘Ã£ chá»n: {custom_formula}")
                else:
                    custom_formula = st.text_input("ğŸ§  Nháº­p cÃ´ng thá»©c KPI tuá»³ chá»‰nh")

                custom_col_name = st.text_input("ğŸ“ TÃªn cá»™t má»›i:", value="KPI tuá»³ biáº¿n")

                if st.button("ğŸš€ TÃ­nh KPI tuá»³ biáº¿n"):
                    if selected_cols and custom_formula and custom_col_name:
                        try:
                            calc_df = df_kpi_total[selected_cols].copy()
                            result = eval(custom_formula, {}, calc_df.to_dict("series"))
                            df_kpi_total[custom_col_name] = pd.to_numeric(result, errors="coerce").round(2)
                            st.success(f"âœ… ÄÃ£ thÃªm cá»™t: {custom_col_name}")
                        except Exception as e:
                            st.error(f"âŒ Lá»—i cÃ´ng thá»©c: {e}")
                    else:
                        st.warning("âš ï¸ Cáº§n chá»n Ä‘á»§ cá»™t, cÃ´ng thá»©c vÃ  tÃªn cá»™t má»›i.")

            


            # df_kpi_total["Hiá»‡u suáº¥t (%)"] = pd.to_numeric(df_kpi_total["Hiá»‡u suáº¥t (%)"], errors="coerce").round(2)
            rename_display = {
                kpi: f"{kpi} ({kpi_label_map.get(kpi, '')})"
                for kpi in kpi_cols if kpi in kpi_label_map
            }




        st.subheader("ğŸ“Š KPI tá»•ng há»£p theo nhÃ¢n viÃªn")
        st.dataframe(df_kpi_total, use_container_width=True)


        # â€”â€”â€”â€”â€”â€” END: TÃNH KPI â€”â€”â€”â€”â€”â€”

        # Táº¡o file Excel trong bá»™ nhá»›
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df_kpi_total.to_excel(writer, index=False, sheet_name='Tá»•ng há»£p')
        output.seek(0)
        processed_data = output.getvalue()
        # NÃºt táº£i vá» file Excel
        st.download_button(
            label="ğŸ“¥ Táº£i dá»¯ liá»‡u tá»•ng há»£p Excel",
            data=processed_data,
            file_name="tong_hop_bao_cao.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)  
        

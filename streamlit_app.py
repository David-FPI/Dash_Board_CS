import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="T·ªïng h·ª£p b√°o c√°o nh√¢n vi√™n", layout="wide")
st.title("üìä T·ªïng h·ª£p b√°o c√°o nh√¢n vi√™n t·ª´ nhi·ªÅu file Excel")

# ======================== H√†m chu·∫©n h√≥a & x·ª≠ l√Ω ========================
def normalize_staff_name(name):
    if not isinstance(name, str):
        return ""
    name = re.sub(r"\(.*?\)", "", name)
    name = re.sub(r"\s+", " ", name).strip()
    return name

def extract_header(df):
    if len(df) < 3:
        raise ValueError("File thi·∫øu d√≤ng ti√™u ƒë·ªÅ (√≠t h∆°n 3 d√≤ng).")
    row1 = df.iloc[1].fillna("")
    row2 = df.iloc[2].fillna("")
    header = row1.astype(str) + " " + row2.astype(str)
    header = header.str.replace(r"\s+", " ", regex=True).str.strip()
    return header

def extract_data_block(df_raw):
    header = extract_header(df_raw)
    header = pd.Series(header)
    header = header.where(~header.duplicated(), header + "_" + header.groupby(header).cumcount().astype(str))
    df_data = df_raw.iloc[3:].copy()

    cutoff_idx = df_data[df_data.iloc[:, 0].astype(str).str.contains("ÁªüËÆ°|T·ªïng", case=False, na=False)].index
    if not cutoff_idx.empty:
        df_data = df_data.loc[:cutoff_idx[0] - 1]

    df_data.columns = header
    df_data.reset_index(drop=True, inplace=True)

    staff_col = next((c for c in df_data.columns if "nh√¢n vi√™n" in c.lower()), None)
    if not staff_col:
        raise ValueError("Kh√¥ng t√¨m th·∫•y c·ªôt Nh√¢n vi√™n.")

    last_name = None
    for i in range(len(df_data)):
        name = df_data.at[i, staff_col]
        if pd.notna(name) and str(name).strip() != "":
            last_name = normalize_staff_name(name)
        elif last_name:
            df_data.at[i, staff_col] = last_name

    return df_data

# ======================== X·ª≠ l√Ω nhi·ªÅu sheet ========================
def process_all_sheets(file):
    xls = pd.ExcelFile(file)
    all_data = []
    log = []
    for sheet in xls.sheet_names:
        try:
            df_raw = xls.parse(sheet, header=None)
            cleaned = extract_data_block(df_raw)
            cleaned["__Sheet__"] = sheet
            all_data.append(cleaned)
            log.append({"Sheet": sheet, "Status": "‚úÖ ƒê√£ x·ª≠ l√Ω", "Rows": len(cleaned)})
        except Exception as e:
            log.append({"Sheet": sheet, "Status": f"‚ùå B·ªè qua - {str(e)}", "Rows": 0})
    log_df = pd.DataFrame(log)
    return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame(), log_df

# ======================== Chu·∫©n h√≥a t√™n c·ªôt ========================
def normalize_column_name(col):
    col = str(col)
    col = re.sub(r"\s+", " ", col)
    col = col.strip().lower()
    return col

# ======================== Giao di·ªán ========================
uploaded_files = st.file_uploader("üìÅ T·∫£i l√™n 1 ho·∫∑c nhi·ªÅu file b√°o c√°o Excel", type=["xlsx"], accept_multiple_files=True)

if uploaded_files:
    full_data = []
    for file in uploaded_files:
        try:
            st.success(f"‚úîÔ∏è ƒêang x·ª≠ l√Ω: {file.name}")
            df_all, sheet_log = process_all_sheets(file)
            df_all["__File__"] = file.name
            full_data.append(df_all)
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω file {file.name}: {e}")

    if full_data:
        df_final = pd.concat(full_data, ignore_index=True)
        # üîç In th·ª≠ c√°c sheet v√† s·ªë c·ªôt nh·∫≠n ƒë∆∞·ª£c t·ª´ m·ªói sheet
        st.markdown("### üìå Check: C·ªôt nh·∫≠n ƒë∆∞·ª£c t·ª´ m·ªói sheet")

        if "__Sheet__" in df_final.columns:
            sheet_col_map = df_final.groupby("__Sheet__").agg(lambda x: list(x.index)).reset_index()
            sheet_col_map["S·ªë d√≤ng"] = sheet_col_map["__Sheet__"].apply(lambda sheet: len(df_final[df_final["__Sheet__"] == sheet]))
            sheet_col_map["S·ªë c·ªôt"] = sheet_col_map["__Sheet__"].apply(lambda sheet: df_final[df_final["__Sheet__"] == sheet].shape[1])
            st.dataframe(sheet_col_map[["__Sheet__", "S·ªë d√≤ng", "S·ªë c·ªôt"]], use_container_width=True)

            # Optional: hi·ªÉn th·ªã 3 d√≤ng ƒë·∫ßu c·ªßa m·ªói sheet
            for sheet in df_final["__Sheet__"].unique():
                st.markdown(f"#### üßæ Sheet: `{sheet}` - 3 d√≤ng ƒë·∫ßu")
                st.dataframe(df_final[df_final["__Sheet__"] == sheet].head(3), use_container_width=True)
        else:
            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt '__Sheet__'. C√≥ th·ªÉ h√†m process_all_sheets() ƒëang b·ªã l·ªói.")




        st.subheader("‚úÖ D·ªØ li·ªáu ƒë√£ t·ªïng h·ª£p")
        st.dataframe(df_final.head(50), use_container_width=True)

        # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî START: T√çNH KPI ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
        normalized_cols = {c: normalize_column_name(c) for c in df_final.columns}

        kpi_ketban_keywords = ["t·ªïng s·ªë k·∫øt b·∫°n trong ng√†y", "ÂΩìÂ§©Âä†zaloÊÄªÊï∞"]
        kpi_tuongtac_keywords = ["t∆∞∆°ng t√°c ‚â•10 c√¢u", "‚â•10"]
        kpi_groupzalo_keywords = ["tham gia group zalo", "l∆∞·ª£ng tham gia group zalo"]
        # --- C√ÅC KPI M·ªû R·ªòNG M·ªöI ---
        kpi_1_1_keywords = ["trao ƒë·ªïi 1-1", "ÁßÅ‰ø°zaloÊï∞", "t·ªïng trao ƒë·ªïi trong ng√†y"]
        kpi_duoi10_keywords = ["ƒë·ªëi tho·∫°i (<10 c√¢u)", "ÂØπËØù (<10 Âè•)", "ƒë·ªëi tho·∫°i", "trao ƒë·ªïi <10 c√¢u", "<10"]
        kpi_khong_phan_hoi_keywords = ["kh√¥ng ph·∫£n h·ªìi", "Êó†ÂõûÂ§ç", "Êó†"]


        def find_cols_by_keywords(keywords):
            return [orig for orig, norm in normalized_cols.items() if any(kw in norm for kw in keywords)]

        def find_col_by_keywords(keywords):
            return next((orig for orig, norm in normalized_cols.items()
                        if any(kw in norm for kw in keywords)), None)

        cols_ketban = find_cols_by_keywords(kpi_ketban_keywords)
        cols_tuongtac = find_cols_by_keywords(kpi_tuongtac_keywords)
        cols_groupzalo = find_cols_by_keywords(kpi_groupzalo_keywords)
        cols_1_1 = find_cols_by_keywords(kpi_1_1_keywords)
        cols_duoi10 = find_cols_by_keywords(kpi_duoi10_keywords)
        cols_khong_phan_hoi = find_cols_by_keywords(kpi_khong_phan_hoi_keywords)

        if not (cols_ketban and cols_tuongtac and cols_groupzalo):
            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m ƒë·ªß 3 c·ªôt KPI (k·∫øt b·∫°n, t∆∞∆°ng t√°c, group Zalo). Vui l√≤ng ki·ªÉm tra l·∫°i t√™n c·ªôt.")
        else:
            df_final["kpi_ketban"] = df_final[cols_ketban].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)
            df_final["kpi_tuongtac_>10"] = df_final[cols_tuongtac].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)
            df_final["kpi_groupzalo"] = df_final[cols_groupzalo].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)
            df_final["kpi_traodoi_1_1"] = df_final[cols_1_1].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)
            df_final["kpi_doi_thoai_<10"] = df_final[cols_duoi10].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)
            df_final["kpi_khong_phan_hoi"] = df_final[cols_khong_phan_hoi].apply(pd.to_numeric, errors="coerce").fillna(0).sum(axis=1)

            # üéØ N√¢ng c·∫•p t√¨m c·ªôt Nh√¢n vi√™n v√† Ngu·ªìn
            staff_keywords = ["nh√¢n vi√™n", "‰∫∫Âëò", "ÊàêÂëò"]
            source_keywords = ["ngu·ªìn", "Ê∏†ÈÅì"]

            staff_col = find_col_by_keywords(staff_keywords)
            source_col = find_col_by_keywords(source_keywords)

            kpi_cols = [
                "kpi_ketban", "kpi_tuongtac_>10", "kpi_groupzalo",
                "kpi_traodoi_1_1", "kpi_doi_thoai_<10", "kpi_khong_phan_hoi"
            ]


            df_kpi = df_final.groupby([staff_col, source_col], as_index=False)[kpi_cols].sum()
            st.subheader("üìà KPI theo nh√¢n vi√™n v√† ngu·ªìn")
            st.dataframe(df_kpi, use_container_width=True)

            df_kpi_total = df_kpi.groupby(staff_col, as_index=False)[kpi_cols].sum()
            df_kpi_total["Hi·ªáu su·∫•t (%)"] = df_kpi_total.apply(
                lambda row: (row["kpi_groupzalo"] / row["kpi_ketban"] * 100) if row["kpi_ketban"] != 0 else None,
                axis=1
            )
            df_kpi_total["Hi·ªáu su·∫•t (%)"] = pd.to_numeric(df_kpi_total["Hi·ªáu su·∫•t (%)"], errors="coerce").round(2)


            st.subheader("üìä KPI t·ªïng h·ª£p theo nh√¢n vi√™n")
            st.dataframe(df_kpi_total, use_container_width=True)

        # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî END: T√çNH KPI ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

        csv = df_final.to_csv(index=False).encode('utf-8-sig')
        st.download_button("üì• T·∫£i d·ªØ li·ªáu t·ªïng h·ª£p CSV", csv, "tong_hop_bao_cao.csv", "text/csv")
